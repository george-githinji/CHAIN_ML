## SHAP
* Code and examples (in the notebooks folder): https://github.com/slundberg/shap
* Original SHAP paper: http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions
* SHAP values explicitly for trees: https://arxiv.org/abs/1802.03888
* Informal blog post: https://medium.com/civis-analytics/demystifying-black-box-models-with-shap-value-analysis-3e20b536fc80
* Another blog post: https://medium.com/@gabrieltseng/interpreting-complex-models-with-shap-values-1c187db6ec83
* Blog post comparing different types of importance/attribution values: https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27

## XGBoost
* Original paper: https://arxiv.org/abs/1603.02754
* Video lecture: http://videolectures.net/kdd2016_chen_boosting_system/
* Code, examples, tutorials, etc:  https://github.com/dmlc/xgboost/tree/master/demo 

## Spectral Clustering
* Super tutorial: http://www.kyb.mpg.de/fileadmin/user_upload/files/publications/attachments/Luxburg07_tutorial_4488%5b0%5d.pdf
* Video tutorial by same person: http://videolectures.net/bootcamp07_luxburg_clu/

